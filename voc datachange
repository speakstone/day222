1.convert_face_seg.sh


set -e

CURRENT_DIR=$(pwd)
WORK_DIR="."

cd "${CURRENT_DIR}"

# Root path for FACE_SEG_ROOT dataset.
FACE_SEG_ROOT="${WORK_DIR}/persion_seg"

# Build TFRecords of the dataset.
# First, create output directory for storing TFRecords.
OUTPUT_DIR="${FACE_SEG_ROOT}/tfrecord"
mkdir -p "${OUTPUT_DIR}"

BUILD_SCRIPT="${WORK_DIR}/build_face_seg_data.py"

echo "Converting FACE_SEG dataset..."
python "${BUILD_SCRIPT}" \
  --FACE_SEG_ROOT="${FACE_SEG_ROOT}" \
  --output_dir="${OUTPUT_DIR}" \




2.build_face_seg_data.py
# -*- coding: utf-8 -*-
"""
Created on Fri Apr 20 14:02:22 2018

@author: lilei0129
"""


import glob
import math
import os.path
import re
import sys
import build_data
import tensorflow as tf
import copy

FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_string('FACE_SEG_ROOT',
                           './persion_seg',
                           'persion_SEG_ROOT dataset root folder.')

tf.app.flags.DEFINE_string(
    'output_dir',
    './tfrecord',
    'Path to save converted SSTable of TensorFlow examples.')


_NUM_SHARDS = {
  'train': 5
}
# A map from data type to folder name that saves the data.
_FOLDERS_MAP = {
    'image': 'images',
    'label': 'annotations',
}

# A map from data type to data format.
_DATA_FORMAT_MAP = {
    'image': 'jpg',
    'label': 'png',
}

def _convert_dataset(dataset_split):
  """Converts the specified dataset split to TFRecord format.

  Args:
    dataset_split: The dataset split (e.g., train, val).

  Raises:
    RuntimeError: If loaded image and label have different shape, or if the
      image file with specified postfix could not be found.
  """
  image_files = []
  label_files = []

  image_dir = os.path.join(FLAGS.FACE_SEG_ROOT, _FOLDERS_MAP["image"], dataset_split)
  label_dir = os.path.join(FLAGS.FACE_SEG_ROOT, _FOLDERS_MAP["label"], dataset_split)
  image_list = sorted(os.listdir(image_dir))
  for i in range(len(image_list)):
    file = image_list[i]
    image_files.append(os.path.join(image_dir, file))
    label_files.append(os.path.join(label_dir, file[:-4] + ".png"))
  
  num_images = len(image_files)
  num_per_shard = int(math.ceil(num_images / float(_NUM_SHARDS[dataset_split])))

  image_reader = build_data.ImageReader('jpg', channels=3)
  label_reader = build_data.ImageReader('png', channels=1)

  for shard_id in range(_NUM_SHARDS[dataset_split]):
    shard_filename = '%s-%05d-of-%05d.tfrecord' % (
        dataset_split, shard_id, _NUM_SHARDS[dataset_split])
    output_filename = os.path.join(FLAGS.output_dir, shard_filename)
    with tf.python_io.TFRecordWriter(output_filename) as tfrecord_writer:
      start_idx = shard_id * num_per_shard
      end_idx = min((shard_id + 1) * num_per_shard, num_images)
      for i in range(start_idx, end_idx):
        sys.stdout.write('\r>> Converting image %d/%d shard %d' % (
            i + 1, num_images, shard_id))
        sys.stdout.flush()
        # Read the image.
        image_data = tf.gfile.FastGFile(image_files[i], 'r').read()
        height, width = image_reader.read_image_dims(image_data)
        # Read the semantic segmentation annotation.
        seg_data = tf.gfile.FastGFile(label_files[i], 'r').read()
        seg_height, seg_width = label_reader.read_image_dims(seg_data)
        if height != seg_height or width != seg_width:
          raise RuntimeError('Shape mismatched between image and label.')
        # Convert to tf example.
        filename = os.path.basename(image_files[i][:-4])
        example = build_data.image_seg_to_tfexample(
            image_data, filename, height, width, seg_data)
        tfrecord_writer.write(example.SerializeToString())
    sys.stdout.write('\n')
    sys.stdout.flush()


def main(unused_argv):
  # Only support converting 'train' sets for now.
  for dataset_split in ['train']:
    _convert_dataset(dataset_split)


if __name__ == '__main__':
  tf.app.run()



3.class_change.py
# -*- coding: utf-8 -*-
"""
Created on Fri Apr 20 14:47:17 2018

@author: lilei0129
"""

import os
import shutil
import numpy as np

from PIL import Image
from scipy.misc import imsave
import cv2

IMAGE_DIR = "./JPEGImages/"
IMAGE_OUT_DIR = "./persion_seg/images/train/"

ANNOTATION_DIR = "./SegmentationClass/"
ANNOTATION_OUT_DIR = "./persion_seg/annotations/train/"

#if not os.path.isdir(ANNOTATION_OUT_DIR): os.makedirs(ANNOTATION_OUT_DIR)

def parse():
    count = 0
    
    for file in os.listdir(ANNOTATION_DIR):
        sight = 0
        if (count + 1) % 300 == 0: print count + 1, "images has been parsed."
        count += 1
#        if (file[-3:] != "ppm"): continue 
        im = cv2.imread(os.path.join(ANNOTATION_DIR, file),0)
        w, h = im.shape[0],im.shape[1]

        for i in range(w):
            for j in range(h):
                if im[i,j] != 147:
                    im[i,j] = 0
                else :
    				   im[i,j] = 1
        sight = im.sum()

        #unique_labels = np.unique(label)
        #print file, unique_labels
        if sight >10 :   
            output_annotation_name = os.path.join(ANNOTATION_OUT_DIR, file[:-4] + ".png")
            imsave(output_annotation_name, im)           
            shutil.copy(os.path.join(IMAGE_DIR, file[:-4] + ".jpg"), os.path.join(IMAGE_OUT_DIR, file[:-4] + ".jpg"))
        else:continue
if __name__ == '__main__':
    parse()
        
